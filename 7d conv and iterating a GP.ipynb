{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['THEANO_FLAGS'] = 'optimizer_including=cudnn, force_device=True, mode=FAST_RUN, device=cuda*, floatX=float64,linker=cvm, optimizer=fast_compile'\n",
    "#print(os.path.expanduser('~/.theanorc.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import theano.gpuarray as pygpu\n",
    "#pygpu.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"MKL_THREADING_LAYER\"]=\"GNU\"\n",
    "#os.environ[\"MKL_NUM_THREADS\"] = \"2\" \n",
    "#os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\" \n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"2\" \n",
    "\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from theano.tensor import fft\n",
    "import pymc3 as pm\n",
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "import theano.tensor.signal.conv\n",
    "import exoplanet as xo\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation function needed for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolation function used in model to obtain comparison points with data \n",
    "def interpolate(x0, y0, x):\n",
    "    x = np.array(x)\n",
    "\n",
    "    idx = np.searchsorted(x0, x)\n",
    "    dl = np.array(x - x0[idx - 1])\n",
    "    dr = np.array(x0[idx] - x)\n",
    "    d = dl + dr\n",
    "    wl = dr / d\n",
    "\n",
    "    return wl * y0[idx - 1] + (1 - wl) * y0[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read photometry catalogue created by my other script\n",
    "photfilename = 'F51_out_REMIR_ROS2.fits'\n",
    "data = fits.getdata(photfilename, 1)\n",
    "\n",
    "# The photometry catalogue contains aperture photometry in 25 different\n",
    "# apertures. If we number them 0..24, they correspond to diameters 1..25 arcsec\n",
    "apno = 10 # This is then 11 arcsec\n",
    "\n",
    "# The photometry catalogue contains photometry for the AGN plus some more\n",
    "# objects in the field, in this case the AGN + 6 more objetcs, so 7 in\n",
    "# total. The AGN is number 1, and the others 2, 3, etc.\n",
    "# This is seen in the column names, which end in _1, _2, etc.\n",
    "# E.g. the column MAG_APER_1 contains the aperture magnitudes (for all\n",
    "# 25 apertures) for the AGN.\n",
    "\n",
    "# Get the aperture magnitudes\n",
    "##foo = data['MAG_APER_1'] # has shape e.g. (767, 25), the 25 being the apertures\n",
    "mag_agn  = data['MAG_APER_1'][:,apno]\n",
    "mag_ref1 = data['MAG_APER_3'][:,apno] # I have found that _3 is good here\n",
    "mag_ref2 = data['MAG_APER_4'][:,apno]\n",
    "\n",
    "# Get the differential magnitudes\n",
    "delta_mag_agn_ref1 = mag_agn - mag_ref1\n",
    "delta_mag_ref2_ref1 = mag_ref2 - mag_ref1\n",
    "\n",
    "# Get the magnitude errors \n",
    "magerr_agn = data['MAGERR_APER_1'][:,apno]\n",
    "magerr_ref1 = data['MAGERR_APER_3'][:,apno]\n",
    "magerr_ref2= data['MAGERR_APER_4'][:,apno]\n",
    "\n",
    "# TODO Here I could loop over the filters, subtracting the median\n",
    "\n",
    "# For simplicity \"extract\" some arrays from the data\n",
    "filt = data['filter']\n",
    "mjd_obs = data['mjd_obs']\n",
    "\n",
    "# A simple plot of the J band differential mags, with the median subtracted\n",
    "# Do 'H' and 'K' in the same way\n",
    "maskJ = (filt == 'J')\n",
    "#print(magerr_ref1[mask])\n",
    "#plt.scatter(mjd_obs[mask], delta_mag_agn_ref1[mask]-np.median(delta_mag_agn_ref1[mask]))\n",
    "plt.errorbar(mjd_obs[maskJ], delta_mag_agn_ref1[maskJ]-np.median(delta_mag_agn_ref1[maskJ]), magerr_ref1[maskJ],fmt='b.')\n",
    "plt.title('test')\n",
    "plt.xlabel('MJD-OBS')\n",
    "plt.ylabel('delta mag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J band data\n",
    "xJ=np.asarray(mjd_obs[maskJ], dtype=float)\n",
    "nJ=len(xJ)\n",
    "XJ = np.reshape(xJ,(nJ,1))\n",
    "yJ=np.asarray(delta_mag_agn_ref1[maskJ]-np.median(delta_mag_agn_ref1[maskJ]), dtype=float)\n",
    "yJerr = np.array(magerr_ref1[maskJ], dtype=float)\n",
    "\n",
    "#H band data\n",
    "maskH = (filt == 'H')\n",
    "xHtemp=np.asarray(mjd_obs[maskH], dtype=float)\n",
    "xH=np.delete(xHtemp,(1,2))\n",
    "nH=len(xH)\n",
    "XH = np.reshape(xH,(nH,1))\n",
    "XH_new=np.linspace(min(XH),max(XH),100,dtype=np.float64)\n",
    "Hdelta_mag_agn_ref1=np.delete(delta_mag_agn_ref1[maskH],(1,2))\n",
    "yH=np.asarray(Hdelta_mag_agn_ref1-np.median(Hdelta_mag_agn_ref1), dtype=float)\n",
    "yHerrtemp = np.asarray(magerr_ref1[maskH], dtype=float)\n",
    "yHerr=np.delete(yHerrtemp,(1,2))\n",
    "\n",
    "#K band data\n",
    "maskK = (filt == 'K')\n",
    "xK=np.asarray(mjd_obs[maskK], dtype=float)\n",
    "nK=len(xK)\n",
    "XK = np.reshape(xK,(nK,1))\n",
    "yK=np.asarray(delta_mag_agn_ref1[maskK]-np.median(delta_mag_agn_ref1[maskK]), dtype=float)\n",
    "yKerr = np.asarray(magerr_ref1[maskK], dtype=float)\n",
    "\n",
    "#g band data\n",
    "maskg = (filt == 'g')\n",
    "gtemp=delta_mag_agn_ref1[maskg]\n",
    "gisnan=~np.isnan(gtemp)\n",
    "xg=np.asarray(mjd_obs[maskg][gisnan], dtype=float)\n",
    "ng=len(xg)\n",
    "Xg = np.reshape(xg,(ng,1))\n",
    "yg=np.asarray(delta_mag_agn_ref1[maskg][gisnan]-np.median(delta_mag_agn_ref1[maskg][gisnan]), dtype=float)\n",
    "ygerr = np.asarray(magerr_ref1[maskg][gisnan], dtype=float)\n",
    "#remove values \n",
    "xg=xg[(yg>-0.4) & (yg<0.4)]\n",
    "ng=len(xg)\n",
    "Xg = np.reshape(xg,(ng,1))\n",
    "ygerr=ygerr[(yg>-0.4) & (yg<0.4)]\n",
    "yg=yg[(yg>-0.4) & (yg<0.4)]\n",
    "\n",
    "#r band data\n",
    "maskr = (filt == 'r')\n",
    "rtemp=delta_mag_agn_ref1[maskr]\n",
    "risnan=~np.isnan(rtemp)\n",
    "xr=np.asarray(mjd_obs[maskr][risnan], dtype=float)\n",
    "nr=len(xr)\n",
    "Xr = np.reshape(xr,(nr,1))\n",
    "yr=np.asarray(delta_mag_agn_ref1[maskr][risnan]-np.median(delta_mag_agn_ref1[maskr][risnan]), dtype=float)\n",
    "yrerr = np.asarray(magerr_ref1[maskr][risnan], dtype=float)\n",
    "#remove values \n",
    "xr=xr[(yr>-0.4) & (yr<0.4)]\n",
    "nr=len(xr)\n",
    "Xr = np.reshape(xr,(nr,1))\n",
    "yrerr=yrerr[(yr>-0.4) & (yr<0.4)]\n",
    "yr=yr[(yr>-0.4) & (yr<0.4)]\n",
    "\n",
    "#i band data\n",
    "maski = (filt == 'i')\n",
    "itemp=delta_mag_agn_ref1[maski]\n",
    "iisnan=~np.isnan(itemp)\n",
    "xi=np.asarray(mjd_obs[maski][iisnan], dtype=float)\n",
    "ni=len(xi)\n",
    "Xi = np.reshape(xi,(ni,1))\n",
    "yi=np.asarray(delta_mag_agn_ref1[maski][iisnan]-np.median(delta_mag_agn_ref1[maski][iisnan]), dtype=float)\n",
    "yierr = np.asarray(magerr_ref1[maski][iisnan], dtype=float)\n",
    "#remove values \n",
    "xi=xi[(yi>-0.4) & (yi<0.4)]\n",
    "ni=len(xi)\n",
    "Xi= np.reshape(xi,(ni,1))\n",
    "yierr=yierr[(yi>-0.4) & (yi<0.4)]\n",
    "yi=yi[(yi>-0.4) & (yi<0.4)]\n",
    "\n",
    "#z band data\n",
    "maskz = (filt == 'z')\n",
    "ztemp=delta_mag_agn_ref1[maskz]\n",
    "zisnan=~np.isnan(ztemp)\n",
    "xz=np.asarray(mjd_obs[maskz][zisnan], dtype=float)\n",
    "nz=len(xz)\n",
    "Xz = np.reshape(xz,(nz,1))\n",
    "yz=np.asarray(delta_mag_agn_ref1[maskz][zisnan]-np.median(delta_mag_agn_ref1[maskz][zisnan]), dtype=float)\n",
    "yzerr = np.asarray(magerr_ref1[maskz][zisnan], dtype=float)\n",
    "#remove values \n",
    "xz=xz[(yz>-0.4) & (yz<0.4)]\n",
    "nz=len(xz)\n",
    "Xz = np.reshape(xz,(nz,1))\n",
    "yzerr=yzerr[(yz>-0.4) & (yz<0.4)]\n",
    "yz=yz[(yz>-0.4) & (yz<0.4)]\n",
    "\n",
    "#time array with all bands\n",
    "#be carefull with how XJ and xj acts \n",
    "X_tot= np.concatenate((xJ,xH,xK,xg,xr,xi,xz),axis=None)\n",
    "X_tot=np.reshape(X_tot,(len(X_tot),1))\n",
    "\n",
    "#combine all y values for guess\n",
    "Y_tot= np.concatenate((yJ,yH,yK),axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xJ, yJ, yJerr,fmt='b.',label='J')\n",
    "plt.errorbar(xH, yH, yHerr,fmt='r.',label='H')\n",
    "plt.errorbar(xK, yK, yKerr,fmt='g.',label='K')\n",
    "plt.errorbar(xg, yg, ygerr,fmt='c.',label='g')\n",
    "plt.errorbar(xr, yr, yrerr,fmt='m.',label='r')\n",
    "plt.errorbar(xi, yi, yierr,fmt='y.',label='i')\n",
    "plt.errorbar(xz, yz, yzerr,fmt='k.',label='z')\n",
    "#plt.ylim(-1,1)\n",
    "plt.title('Light curves')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Delta mag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XJ,yJ,yJerr = np.loadtxt('redJband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "XH,yH,yHerr = np.loadtxt('redHband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "XK,yK,yKerr = np.loadtxt('redKband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "Xg,yg,ygerr = np.loadtxt('redgband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "Xr,yr,yrerr = np.loadtxt('redrband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "Xi,yi,yierr = np.loadtxt('rediband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "Xz,yz,yzerr = np.loadtxt('redzband.txt', delimiter=',', usecols=(0,1,2), unpack=True)\n",
    "X_tot=[XJ,XH,XK,Xg,Xr,Xi,Xz]\n",
    "plt.errorbar(XJ, yJ, yJerr, fmt='b.', label='J')\n",
    "plt.errorbar(XH, yH, yHerr, fmt='r.', label='H')\n",
    "plt.errorbar(XK, yK, yKerr, fmt='g.', label='K')\n",
    "plt.errorbar(Xg, yg, ygerr, fmt='c.', label='g')\n",
    "plt.errorbar(Xr, yr, yrerr, fmt='m.', label='r')\n",
    "plt.errorbar(Xi, yi, yierr, fmt='y.', label='i')\n",
    "plt.errorbar(Xz, yz, yzerr, fmt='k.', label='z')\n",
    "plt.title('Light curves')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Delta mag')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array for GP\n",
    "nGP=601\n",
    "XGP=np.linspace(np.min(X_tot),np.max(X_tot),nGP)\n",
    "XGP=np.reshape(XGP,(len(XGP),1))\n",
    "#time delay array\n",
    "ntau=nGP\n",
    "tau=np.linspace(0.0,100.0,ntau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.variational.callbacks import CheckParametersConvergence\n",
    "#tracker = pm.callbacks.Tracker(\n",
    "#    mean=advi.approx.mean.eval,  # callable that returns mean\n",
    "#    std=advi.approx.std.eval  # callable that returns std\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as convmodel:\n",
    "    ############################################\n",
    "    #define driving function as Gaussian Process\n",
    "    ############################################\n",
    "    #find way to use g band as first guess of value \n",
    "    ℓ = pm.TruncatedNormal('ℓ', mu=0.70710678118, sigma=0.70710678118, lower=0.0)#timescale of variation for the driving function, order of days for UV\n",
    "    #REMEMBER time scale is 2*ℓ^2 so remember to rewrite as ℓ_true=2*ℓ^2\n",
    "    η = pm.TruncatedNormal('η', mu=0.5, sigma=0.5, lower=0.0)#long term standard deviation for the driving function\n",
    "    cov = η**2 * pm.gp.cov.Exponential(1, ls=ℓ)#using same cov as light curve interpolation\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    f = gp.prior(\"f\", X=XGP)\n",
    "    f = f.reshape((1,1,len(XGP),1))\n",
    "    ##############\n",
    "    #Define priors\n",
    "    ##############\n",
    "    mmu=3.91202300543#50\n",
    "    msig=3.91202300543\n",
    "    mlow=2.3#10\n",
    "    sigmu=2.0\n",
    "    sigsig=1.0\n",
    "    siglow=1.0\n",
    "    #Universal Dusty Torus parameters for the uniform temperature DT\n",
    "    sigma_DT=pm.TruncatedNormal('sigma_DT', mu=sigmu,sigma=sigsig,lower=siglow)#needs a source for scale\n",
    "    m_DT=pm.TruncatedNormal('m_DT', mu=3.91202300543,sigma=3.91202300543,lower=mlow)#we expect serveral tens to hundreds of days from the nature letter\n",
    "    theta_DT=pm.TruncatedNormal('theta_DT', mu=3.91202300543,sigma=3.91202300543,lower=0.0,upper=4.5)#add later when simple model is staple\n",
    "    #Accretion Disk paramters\n",
    "    #J band\n",
    "    Jsigma_AD=pm.TruncatedNormal('Jsigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    Jtheta_AD=pm.Normal('Jtheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    Jm_AD=pm.TruncatedNormal('Jm_AD', mu=3.91202300543 ,sigma=3.91202300543,lower=mlow)#AD has 3-5 times smaller lags than DT \n",
    "    #H band\n",
    "    Hsigma_AD=pm.TruncatedNormal('Hsigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    Htheta_AD=pm.Normal('Htheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    Hm_AD=pm.TruncatedNormal('Hm_AD', mu=3.91202300543 ,sigma=3.91202300543 ,lower=mlow)#AD has 3-5 times smaller lags than DT \n",
    "    #K band\n",
    "    Ksigma_AD=pm.TruncatedNormal('Ksigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    Ktheta_AD=pm.Normal('Ktheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    Km_AD=pm.TruncatedNormal('Km_AD', mu=3.91202300543 ,sigma=3.91202300543,lower=mlow)#AD has 3-5 times smaller lags than DT  \n",
    "    #g band\n",
    "    gsigma_AD=pm.TruncatedNormal('gsigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    gtheta_AD=pm.Normal('gtheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    gm_AD=pm.TruncatedNormal('gm_AD', mu=3.91202300543 ,sigma=3.91202300543 ,lower=mlow)#AD has 3-5 times smaller lags than DT  \n",
    "    #r band\n",
    "    rsigma_AD=pm.TruncatedNormal('rsigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    rtheta_AD=pm.Normal('rtheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    rm_AD=pm.TruncatedNormal('rm_AD', mu=3.91202300543 ,sigma=3.91202300543 ,lower=mlow)#AD has 3-5 times smaller lags than DT  \n",
    "    #i band\n",
    "    isigma_AD=pm.TruncatedNormal('isigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    itheta_AD=pm.Normal('itheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    im_AD=pm.TruncatedNormal('im_AD', mu=3.91202300543 ,sigma=3.91202300543 ,lower=mlow)#AD has 3-5 times smaller lags than DT\n",
    "    #z band\n",
    "    zsigma_AD=pm.TruncatedNormal('zsigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    ztheta_AD=pm.Normal('ztheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    zm_AD=pm.TruncatedNormal('zm_AD', mu=3.91202300543 ,sigma=3.91202300543 ,lower=mlow)#AD has 3-5 times smaller lags than DT\n",
    "    #BB and power law parameters\n",
    "    T=pm.TruncatedNormal('T', mu=np.log(1400),sigma=0.072,lower=np.log(1000.0),upper=np.log(2300.0))#taken from nature letter\n",
    "    K_0=pm.TruncatedNormal('K_0', mu=0.0,sigma=2.3,upper=2.3)#powr/BB\n",
    "    index=pm.Normal('index', mu=1.5, sigma=0.5)#sign depends on diffmag definition change to -2 to -1\n",
    "    #Note for index: we have taken the transformation from F_nu to F_lamb into account with the index value.\n",
    "                         \n",
    "    #Different wavelength for different bands, not a free paramter \n",
    "    #REMIR filters in nm\n",
    "    Jwav = 1250.0\n",
    "    Hwav = 1625.0\n",
    "    Kwav = 2150.0\n",
    "    #Sloan filters for ROSS2 in nm\n",
    "    gwav = 475.4\n",
    "    rwav = 620.4\n",
    "    iwav = 769.8\n",
    "    zwav = 966.5\n",
    "\n",
    "    #Define constants \n",
    "    wav_0 = 1122.4#Reference wavelength in nm, use 500?\n",
    "    h = 6.626e-34#Plancks constant in J*s\n",
    "    c = 299792458.0#speed of light in m/s\n",
    "    k = 1.38e-23#Boltzmanns constant in J/K\n",
    "    \n",
    "    #Peak Black Body from uniform torus temperature\n",
    "    #wav_peak = 2.898*10**6/tt.exp(T)\n",
    "    #b_max = 4.967#h*c/(1e-9*wav_peak*k*tt.exp(T))\n",
    "    #BB_max = 1.0/( (wav_peak**5) * (tt.exp(b_max) - 1.0) )\n",
    "    BB_max = -79.3575 + 5*T\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((tt.log((tau-tt.exp(theta_DT))/tt.exp(m_DT)))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-tt.exp(theta_DT))*sigma_DT*tt.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*tt.exp(exp_DT)\n",
    "    lognorm_DT = tt.switch(tt.isnan(lognorm_DT), 0.0, lognorm_DT)\n",
    "    \n",
    "    #Dusty Torus transfer equation for J band\n",
    "    #Jb = h*c/(1e-9*Jwav*k*tt.exp(T))\n",
    "    #JBB = (1.0/( Jwav**5 * (tt.exp(Jb) - 1.0) ))/BB_max\n",
    "    #JPsi_DT = JBB*lognorm_DT\n",
    "    Jb = 11510.0/tt.exp(T)\n",
    "    JBB = -35.654494151481735-tt.log(tt.exp(Jb) - 1.0)\n",
    "    JPsi_DT = (tt.exp(JBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for H band\n",
    "    Hb = 8854.0/tt.exp(T)\n",
    "    HBB = -36.966315473819186-tt.log(tt.exp(Hb) - 1.0)\n",
    "    HPsi_DT = (tt.exp(HBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for K band\n",
    "    Kb = 6692.0/tt.exp(T)\n",
    "    KBB = -38.36611560560854-tt.log(tt.exp(Kb) - 1.0)\n",
    "    KPsi_DT = (tt.exp(KBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for g band\n",
    "    gb = 30265.0/tt.exp(T)\n",
    "    gBB = -30.82078277463-tt.log(tt.exp(gb) - 1.0)\n",
    "    gPsi_DT = (tt.exp(gBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for r band\n",
    "    rb = 23191.0/tt.exp(T)\n",
    "    rBB = -32.15182215651192-tt.log(tt.exp(rb) - 1.0)\n",
    "    rPsi_DT = (tt.exp(rBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for i band\n",
    "    ib = 18690.0/tt.exp(T)\n",
    "    iBB = -33.230653704248226-tt.log(tt.exp(ib) - 1.0)\n",
    "    iPsi_DT = (tt.exp(iBB)/tt.exp(BB_max))*lognorm_DT \n",
    "    #Dusty Torus transfer equation for z band\n",
    "    zb = 14886.0/tt.exp(T)\n",
    "    zBB = -34.36840649324193-tt.log(tt.exp(zb) - 1.0)\n",
    "    zPsi_DT = (tt.exp(zBB)/tt.exp(BB_max))*lognorm_DT \n",
    "    \n",
    "    #Accretion Disk transfer equation for the J band\n",
    "    Jpowr = K_0+0.1076743015081*index    \n",
    "    Jexp_AD = -((tt.log((tau-Jtheta_AD)/tt.exp(Jm_AD)))**2/(2*Jsigma_AD**2))\n",
    "    Jfront_AD = 1.0/((tau-Jtheta_AD)*Jsigma_AD*tt.sqrt(2*np.pi))\n",
    "    Jlognorm_AD = Jfront_AD*tt.exp(Jexp_AD)\n",
    "    Jlognorm_AD = tt.switch(tt.isnan(Jlognorm_AD), 0.0, Jlognorm_AD)\n",
    "    JPsi_AD = tt.exp(Jpowr)*Jlognorm_AD\n",
    "    #Accretion Disk transfer equation for the H band\n",
    "    Hpowr = K_0+0.3700385659755865*index    \n",
    "    Hexp_AD = -((tt.log((tau-Htheta_AD)/tt.exp(Hm_AD)))**2/(2*Hsigma_AD**2))\n",
    "    Hfront_AD = 1.0/((tau-Htheta_AD)*Hsigma_AD*tt.sqrt(2*np.pi))\n",
    "    Hlognorm_AD = Hfront_AD*tt.exp(Hexp_AD)\n",
    "    Hlognorm_AD = tt.switch(tt.isnan(Hlognorm_AD), 0.0, Hlognorm_AD)\n",
    "    HPsi_AD = tt.exp(Hpowr)*Hlognorm_AD\n",
    "    #Accretion Disk transfer equation for the K band\n",
    "    Kpowr = K_0+0.649998592333457*index    \n",
    "    Kexp_AD = -((tt.log((tau-Ktheta_AD)/tt.exp(Km_AD)))**2/(2*Ksigma_AD**2))\n",
    "    Kfront_AD = 1.0/((tau-Ktheta_AD)*Ksigma_AD*tt.sqrt(2*np.pi))\n",
    "    Klognorm_AD = Kfront_AD*tt.exp(Kexp_AD)\n",
    "    Klognorm_AD = tt.switch(tt.isnan(Klognorm_AD), 0.0, Klognorm_AD)\n",
    "    KPsi_AD = tt.exp(Kpowr)*Klognorm_AD\n",
    "    #Accretion Disk transfer equation for the g band\n",
    "    gpowr = K_0-0.8590679738621576*index    \n",
    "    gexp_AD = -((tt.log((tau-gtheta_AD)/tt.exp(gm_AD)))**2/(2*gsigma_AD**2))\n",
    "    gfront_AD = 1.0/((tau-gtheta_AD)*gsigma_AD*tt.sqrt(2*np.pi))\n",
    "    glognorm_AD = gfront_AD*tt.exp(gexp_AD)\n",
    "    glognorm_AD = tt.switch(tt.isnan(glognorm_AD), 0.0, glognorm_AD)\n",
    "    gPsi_AD = tt.exp(gpowr)*glognorm_AD\n",
    "    #Accretion Disk transfer equation for the r band\n",
    "    rpowr = K_0-0.5928600974858673*index    \n",
    "    rexp_AD = -((tt.log((tau-rtheta_AD)/tt.exp(rm_AD)))**2/(2*rsigma_AD**2))\n",
    "    rfront_AD = 1.0/((tau-rtheta_AD)*rsigma_AD*tt.sqrt(2*np.pi))\n",
    "    rlognorm_AD = rfront_AD*tt.exp(rexp_AD)\n",
    "    rlognorm_AD = tt.switch(tt.isnan(rlognorm_AD), 0.0, rlognorm_AD)\n",
    "    rPsi_AD = tt.exp(rpowr)*rlognorm_AD\n",
    "    #Accretion Disk transfer equation for the i band\n",
    "    ipowr = K_0-0.3770937879386054*index    \n",
    "    iexp_AD = -((tt.log((tau-itheta_AD)/tt.exp(im_AD)))**2/(2*isigma_AD**2))\n",
    "    ifront_AD = 1.0/((tau-itheta_AD)*isigma_AD*tt.sqrt(2*np.pi))\n",
    "    ilognorm_AD = ifront_AD*tt.exp(iexp_AD)\n",
    "    ilognorm_AD = tt.switch(tt.isnan(ilognorm_AD), 0.0, ilognorm_AD)\n",
    "    iPsi_AD = tt.exp(ipowr)*ilognorm_AD\n",
    "    #Accretion Disk transfer equation for the z band\n",
    "    zpowr = K_0-0.1495432301398658*index    \n",
    "    zexp_AD = -((tt.log((tau-ztheta_AD)/tt.exp(zm_AD)))**2/(2*zsigma_AD**2))\n",
    "    zfront_AD = 1.0/((tau-ztheta_AD)*zsigma_AD*tt.sqrt(2*np.pi))\n",
    "    zlognorm_AD = zfront_AD*tt.exp(zexp_AD)\n",
    "    zlognorm_AD = tt.switch(tt.isnan(zlognorm_AD), 0.0, zlognorm_AD)\n",
    "    zPsi_AD = tt.exp(zpowr)*zlognorm_AD\n",
    "    \n",
    "    #########################\n",
    "    #Full transfer equations\n",
    "    #########################\n",
    "    Jtransfer = JPsi_DT + JPsi_AD\n",
    "    Jtransfer = Jtransfer.reshape(((1,1,len(tau),1)))\n",
    "    Htransfer = HPsi_DT + HPsi_AD\n",
    "    Htransfer = Htransfer.reshape(((1,1,len(tau),1)))\n",
    "    Ktransfer = KPsi_DT + KPsi_AD\n",
    "    Ktransfer = Ktransfer.reshape(((1,1,len(tau),1)))\n",
    "    gtransfer = gPsi_DT + gPsi_AD\n",
    "    gtransfer = gtransfer.reshape(((1,1,len(tau),1)))\n",
    "    rtransfer = rPsi_DT + rPsi_AD\n",
    "    rtransfer = rtransfer.reshape(((1,1,len(tau),1)))\n",
    "    itransfer = iPsi_DT + iPsi_AD\n",
    "    itransfer = itransfer.reshape(((1,1,len(tau),1)))\n",
    "    ztransfer = zPsi_DT + zPsi_AD\n",
    "    ztransfer = ztransfer.reshape(((1,1,len(tau),1)))\n",
    "    \n",
    "    #The convolutions\n",
    "    ######################################################################\n",
    "    #'half': pad input with a symmetric border of filter rows // 2\n",
    "    #rows and filter columns // 2 columns, then perform a valid convolution. \n",
    "    #For filters with an odd number of rows and columns, \n",
    "    #this leads to the output shape being equal to the input shape.\n",
    "    ######################################################################\n",
    "    Jconvol=theano.tensor.nnet.conv2d(f,Jtransfer,border_mode='half')\n",
    "    Jcomp=interpolate(XGP[:,0],Jconvol[0,0,:,0],XJ)\n",
    "    Hconvol=theano.tensor.nnet.conv2d(f,Htransfer,border_mode='half')\n",
    "    Hcomp=interpolate(XGP[:,0],Hconvol[0,0,:,0],XH)                     \n",
    "    Kconvol=theano.tensor.nnet.conv2d(f,Ktransfer,border_mode='half')\n",
    "    Kcomp=interpolate(XGP[:,0],Kconvol[0,0,:,0],XK)\n",
    "    gconvol=theano.tensor.nnet.conv2d(f,gtransfer,border_mode='half')\n",
    "    gcomp=interpolate(XGP[:,0],gconvol[0,0,:,0],Xg)\n",
    "    rconvol=theano.tensor.nnet.conv2d(f,rtransfer,border_mode='half')\n",
    "    rcomp=interpolate(XGP[:,0],rconvol[0,0,:,0],Xr)\n",
    "    iconvol=theano.tensor.nnet.conv2d(f,itransfer,border_mode='half')\n",
    "    icomp=interpolate(XGP[:,0],iconvol[0,0,:,0],Xi)\n",
    "    zconvol=theano.tensor.nnet.conv2d(f,ztransfer,border_mode='half')\n",
    "    zcomp=interpolate(XGP[:,0],zconvol[0,0,:,0],Xz)\n",
    "    #Define likelihoods\n",
    "    #kJ = pm.TruncatedNormal('kJ', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)#Noise boost factor\n",
    "    #kH = pm.TruncatedNormal('kH', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #kK = pm.TruncatedNormal('kK', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #kg = pm.TruncatedNormal('kg', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #kr = pm.TruncatedNormal('kr', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #ki = pm.TruncatedNormal('ki', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #kz = pm.TruncatedNormal('kz', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    Jlikelihood = pm.Normal('yJ', mu=Jcomp, sigma=yJerr, observed=yJ)\n",
    "    Hlikelihood = pm.Normal('yH', mu=Hcomp, sigma=yHerr, observed=yH)\n",
    "    Klikelihood = pm.Normal('yK', mu=Kcomp, sigma=yKerr, observed=yK)\n",
    "    glikelihood = pm.Normal('yg', mu=gcomp, sigma=ygerr, observed=yg)\n",
    "    rlikelihood = pm.Normal('yr', mu=rcomp, sigma=yrerr, observed=yr)\n",
    "    ilikelihood = pm.Normal('yi', mu=icomp, sigma=yierr, observed=yi)\n",
    "    zlikelihood = pm.Normal('yz', mu=zcomp, sigma=yzerr, observed=yz)\n",
    "    #the shape of mu and observed needs to be the same\n",
    "    ######################################################################\n",
    "    #max_treedepth, default=10\n",
    "    #The maximum tree depth. Trajectories are stopped when this depth is reached.\n",
    "    #early_max_treedepth, default=8\n",
    "    #The maximum tree depth during the first 200 tuning samples.\n",
    "    ###################################################################### \n",
    "    \n",
    "    #tracetransfer = pm.sample(5000,tune=2000,init='auto',chains=1,cores=8)\n",
    "    #tracetransfer = pm.sample(5000,tune=2000,init='advi+adapt_diag',chains=1,cores=8)\n",
    "    #map_soln = xo.optimize(start=convmodel.test_point,method='trust-constr')\n",
    "    tracetransfer = pm.sample(draws=5000,tune=2000,chains=1,cores=8,step= xo.get_dense_nuts_step(target_accept=0.8))\n",
    "    #tracetransfer= pm.fit(300, method='svgd', inf_kwargs=dict(n_particles=100))\n",
    "    #tracetransfer= pm.fit(107800,method='advi', callbacks=[CheckParametersConvergence()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Do\n",
    "#do noise boost factor for different bands\n",
    "#try to implement in stan or pymc4 if pymc3 fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['index', 'K_0', 'T', \n",
    "       'zm_AD', 'ztheta_AD', 'zsigma_AD', \n",
    "       'im_AD', 'itheta_AD', 'isigma_AD', \n",
    "       'rm_AD', 'rtheta_AD', 'rsigma_AD', \n",
    "       'gm_AD', 'gtheta_AD', 'gsigma_AD', \n",
    "       'Km_AD', 'Ktheta_AD', 'Ksigma_AD', \n",
    "       'Hm_AD', 'Htheta_AD', 'Hsigma_AD', \n",
    "       'Jm_AD', 'Jtheta_AD', 'Jsigma_AD', \n",
    "       'theta_DT', 'm_DT', 'sigma_DT', 'η', 'ℓ']\n",
    "#stepsize should be similar\n",
    "plt.plot(tracetransfer['step_size_bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(tracetransfer.sample(1000),var_names=names ,color='LightSeaGreen');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "accept = tracetransfer.get_sampler_stats('mean_tree_accept', burn=1000)\n",
    "sb.distplot(accept, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#energy plot should be similar \n",
    "energy = tracetransfer['energy']\n",
    "energy_diff = np.diff(energy)\n",
    "sb.distplot(energy - energy.mean(), label='energy')\n",
    "sb.distplot(energy_diff, label='energy diff')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of all the GP variables\n",
    "pm.plot_forest(tracetransfer,\n",
    "               kind='ridgeplot',\n",
    "               var_names=['f'],\n",
    "               combined=False,\n",
    "               ridgeplot_overlap=3,\n",
    "               ridgeplot_alpha=.25,\n",
    "               colors='white',\n",
    "               figsize=(9, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(tracetransfer,names)#.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(tracetransfer, var_names=names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(tracetransfer,names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.pairplot(tracetransfer, var_names=names, divergences=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "\n",
    "# plot the samples from the gp posterior with samples and shading\n",
    "from pymc3.gp.util import plot_gp_dist\n",
    "plot_gp_dist(ax, tracetransfer[\"f\"], XGP);\n",
    "\n",
    "# plot the data and the true latent function\n",
    "#plt.plot(X, y, 'ok', ms=3, alpha=0.5, label=\"Observed data\");\n",
    "\n",
    "# axis labels and title\n",
    "plt.xlabel(\"time\"); plt.ylabel(\"delta mag\");\n",
    "plt.title(\"Driving function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = 1001\n",
    "X_new = np.linspace(min(X_tot), max(X_tot), n_new)\n",
    "\n",
    "# add the GP conditional to the model, given the new X values\n",
    "with convmodel:\n",
    "    f_tot = gp.conditional(\"f_tot\", X_new)\n",
    "\n",
    "# Sample from the GP conditional distribution\n",
    "with convmodel:\n",
    "    pred_samples = pm.sample_posterior_predictive(tracetransfer, vars=[f_tot], samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "\n",
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "plot_gp_dist(ax, pred_samples[\"f_new\"], X_new);\n",
    "#plt.plot(X, y, 'ok', ms=3, alpha=0.5, label=\"Observed data\");\n",
    "plt.xlabel(\"X\"); plt.ylabel(\"f(X)\");\n",
    "plt.title(\"Conditional distribution of f_*, given f\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean and standard deviation of the traces. \n",
    "mu = np.zeros(len(X_new))\n",
    "sd = np.zeros(len(X_new))\n",
    "\n",
    "for i in range(0,len(X_new)):\n",
    "    mu[i] = np.mean(pred_samples[\"f_tot\"][:,i])\n",
    "    sd[i] = np.std(pred_samples[\"f_tot\"][:,i])\n",
    "\n",
    "# draw plot\n",
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "\n",
    "# plot mean and 1σ intervals\n",
    "#plt.plot(X_new, mu, 'r', lw=2, label=\"mean and 1σ region\");\n",
    "#plt.plot(X_new, mu + 1*sd, 'r', lw=1); plt.plot(X_new, mu - 1*sd, 'r', lw=1);\n",
    "#plt.fill_between(X_new.flatten(), mu - 1*sd, mu + 1*sd, color=\"r\", alpha=0.5)\n",
    "plt.errorbar(X_tot,mu,sd,fmt='r.',label='Driving function value at data points')\n",
    "\n",
    "# plot original data and true function\n",
    "#plt.plot(X, y, 'ok', ms=3, alpha=1.0, label=\"observed data\")\n",
    "#plt.errorbar(X, y, yerr,fmt='.',label=\"observed data\")\n",
    "\n",
    "plt.xlabel(\"t\");\n",
    "plt.ylabel(\"diffmag\")\n",
    "plt.title(\"predictive mean and 1σ interval\"); plt.legend();\n",
    "print(np.mean(sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xJ, yJ, yJerr,fmt='b.',label='J')\n",
    "plt.errorbar(xH, yH, yHerr,fmt='g.',label='H')\n",
    "plt.errorbar(xK, yK, yKerr,fmt='r.',label='K')\n",
    "plt.errorbar(X_tot,mu,sd,fmt='k.',label='Driving')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check transfer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfertest(theta,tau):\n",
    "    (sigma_DT, m_DT, theta_DT, \n",
    "     Jsigma_AD, Jm_AD, Jtheta_AD,\n",
    "     Hsigma_AD, Hm_AD, Htheta_AD,\n",
    "     Ksigma_AD, Km_AD, Ktheta_AD,\n",
    "     gsigma_AD, gm_AD, gtheta_AD,\n",
    "     rsigma_AD, rm_AD, rtheta_AD,\n",
    "     isigma_AD, im_AD, itheta_AD,\n",
    "     zsigma_AD, zm_AD, ztheta_AD,\n",
    "     T, K_0, index)= theta\n",
    "    \n",
    "    T=np.exp(T)\n",
    "    theta_DT=np.exp(theta_DT)\n",
    "    #Different wavelength for different bands, not a free paramter \n",
    "    #REMIR filters in nm\n",
    "    Jwav = 1250.0\n",
    "    Hwav = 1625.0\n",
    "    Kwav = 2150.0\n",
    "    #Sloan filters for ROSS2 in nm\n",
    "    gwav = 475.4\n",
    "    rwav = 620.4\n",
    "    iwav = 769.8\n",
    "    zwav = 966.5\n",
    "\n",
    "    #Define constants \n",
    "    wav_0 = 1122.4#Reference wavelength in nm, use 500?\n",
    "    h = 6.626e-34#Plancks constant in J*s\n",
    "    c = 299792458.0#speed of light in m/s\n",
    "    k = 1.38e-23#Boltzmanns constant in J/K\n",
    "    #Peak Black Body from uniform torus temperature\n",
    "    wav_peak = 2.898*10**6/T\n",
    "    b_max = 4.967#h*c/(1e-9*wav_peak*k*T)\n",
    "    BB_max = 1.0/( (wav_peak**5) * (np.exp(b_max) - 1.0) )\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((np.log((tau-theta_DT)/np.exp(m_DT)))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-theta_DT)*sigma_DT*np.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*np.exp(exp_DT)\n",
    "    where_are_NaNsDT = np.isnan(lognorm_DT)\n",
    "    lognorm_DT[where_are_NaNsDT] = 0.0\n",
    "    \n",
    "    #Dusty Torus transfer equation for J band\n",
    "    #Jb = h*c/(1e-9*Jwav*k*T)\n",
    "    #JBB = (1.0/( Jwav**5 * (np.exp(Jb) - 1.0) ))/BB_max\n",
    "    #JPsi_DT = JBB*lognorm_DT\n",
    "    \n",
    "    #Dusty Torus transfer equation for H band\n",
    "    Hb = h*c/(1e-9*Hwav*k*T)\n",
    "    HBB = (1.0/( Hwav**5 * (np.exp(Hb) - 1.0) ))/BB_max\n",
    "    HPsi_DT = HBB*lognorm_DT\n",
    "    #Dusty Torus transfer equation for K band\n",
    "    Kb = h*c/(1e-9*Kwav*k*T)\n",
    "    KBB = (1.0/( Kwav**5 * (np.exp(Kb) - 1.0) ))/BB_max\n",
    "    KPsi_DT = KBB*lognorm_DT\n",
    "    #Dusty Torus transfer equation for g band\n",
    "    gb = h*c/(1e-9*gwav*k*T)\n",
    "    gBB = (1.0/( gwav**5 * (np.exp(gb) - 1.0) ))/BB_max\n",
    "    gPsi_DT = gBB*lognorm_DT   \n",
    "    #Dusty Torus transfer equation for r band\n",
    "    rb = h*c/(1e-9*rwav*k*T)\n",
    "    rBB = (1.0/( rwav**5 * (np.exp(rb) - 1.0) ))/BB_max\n",
    "    rPsi_DT = rBB*lognorm_DT\n",
    "    #Dusty Torus transfer equation for i band\n",
    "    ib = h*c/(1e-9*iwav*k*T)\n",
    "    iBB = (1.0/( iwav**5 * (np.exp(ib) - 1.0) ))/BB_max\n",
    "    iPsi_DT = iBB*lognorm_DT\n",
    "    #Dusty Torus transfer equation for z band\n",
    "    zb = h*c/(1e-9*zwav*k*T)\n",
    "    zBB = (1.0/( zwav**5 * (np.exp(zb) - 1.0) ))/BB_max\n",
    "    zPsi_DT = zBB*lognorm_DT\n",
    "    \n",
    "    #Accretion Disk transfer equation for the J band\n",
    "    Jpowr = K_0*(Jwav/wav_0)**(index)    \n",
    "    Jexp_AD = -((np.log((tau-Jtheta_AD)/np.exp(Jm_AD)))**2/(2*Jsigma_AD**2))\n",
    "    Jfront_AD = 1.0/((tau-Jtheta_AD)*Jsigma_AD*np.sqrt(2*np.pi))\n",
    "    Jlognorm_AD = Jfront_AD*np.exp(Jexp_AD)\n",
    "    Jwhere_are_NaNs = np.isnan(Jlognorm_AD)\n",
    "    Jlognorm_AD[Jwhere_are_NaNs] = 0.0\n",
    "    JPsi_AD = Jpowr*Jlognorm_AD\n",
    "    #Accretion Disk transfer equation for the H band\n",
    "    Hpowr = K_0*(Hwav/wav_0)**(index)    \n",
    "    Hexp_AD = -((np.log((tau-Htheta_AD)/np.exp(Hm_AD)))**2/(2*Hsigma_AD**2))\n",
    "    Hfront_AD = 1.0/((tau-Htheta_AD)*Hsigma_AD*np.sqrt(2*np.pi))\n",
    "    Hlognorm_AD = Hfront_AD*np.exp(Hexp_AD)\n",
    "    Hwhere_are_NaNs = np.isnan(Hlognorm_AD)\n",
    "    Hlognorm_AD[Hwhere_are_NaNs] = 0.0\n",
    "    HPsi_AD = Hpowr*Hlognorm_AD\n",
    "    #Accretion Disk transfer equation for the K band\n",
    "    Kpowr = K_0*(Kwav/wav_0)**(index)    \n",
    "    Kexp_AD = -((np.log((tau-Ktheta_AD)/np.exp(Km_AD)))**2/(2*Ksigma_AD**2))\n",
    "    Kfront_AD = 1.0/((tau-Ktheta_AD)*Ksigma_AD*np.sqrt(2*np.pi))\n",
    "    Klognorm_AD = Kfront_AD*np.exp(Kexp_AD)\n",
    "    Kwhere_are_NaNs = np.isnan(Klognorm_AD)\n",
    "    Klognorm_AD[Kwhere_are_NaNs] = 0.0\n",
    "    KPsi_AD = Kpowr*Klognorm_AD\n",
    "    #Accretion Disk transfer equation for the g band\n",
    "    gpowr = K_0*(gwav/wav_0)**(index)    \n",
    "    gexp_AD = -((np.log((tau-gtheta_AD)/np.exp(gm_AD)))**2/(2*gsigma_AD**2))\n",
    "    gfront_AD = 1.0/((tau-gtheta_AD)*gsigma_AD*np.sqrt(2*np.pi))\n",
    "    glognorm_AD = gfront_AD*np.exp(gexp_AD)\n",
    "    gwhere_are_NaNs = np.isnan(glognorm_AD)\n",
    "    glognorm_AD[gwhere_are_NaNs] = 0.0\n",
    "    gPsi_AD = gpowr*glognorm_AD\n",
    "    #Accretion Disk transfer equation for the r band\n",
    "    rpowr = K_0*(rwav/wav_0)**(index)    \n",
    "    rexp_AD = -((np.log((tau-rtheta_AD)/np.exp(rm_AD)))**2/(2*rsigma_AD**2))\n",
    "    rfront_AD = 1.0/((tau-rtheta_AD)*rsigma_AD*np.sqrt(2*np.pi))\n",
    "    rlognorm_AD = rfront_AD*np.exp(rexp_AD)\n",
    "    rwhere_are_NaNs = np.isnan(rlognorm_AD)\n",
    "    rlognorm_AD[rwhere_are_NaNs] = 0.0\n",
    "    rPsi_AD = rpowr*rlognorm_AD\n",
    "    #Accretion Disk transfer equation for the i band\n",
    "    ipowr = K_0*(iwav/wav_0)**(index)    \n",
    "    iexp_AD = -((np.log((tau-itheta_AD)/np.exp(im_AD)))**2/(2*isigma_AD**2))\n",
    "    ifront_AD = 1.0/((tau-itheta_AD)*isigma_AD*np.sqrt(2*np.pi))\n",
    "    ilognorm_AD = ifront_AD*np.exp(iexp_AD)\n",
    "    iwhere_are_NaNs = np.isnan(ilognorm_AD)\n",
    "    ilognorm_AD[iwhere_are_NaNs] = 0.0\n",
    "    iPsi_AD = ipowr*ilognorm_AD\n",
    "    #Accretion Disk transfer equation for the z band\n",
    "    zpowr = K_0*(zwav/wav_0)**(index)    \n",
    "    zexp_AD = -((np.log((tau-ztheta_AD)/np.exp(zm_AD)))**2/(2*zsigma_AD**2))\n",
    "    zfront_AD = 1.0/((tau-ztheta_AD)*zsigma_AD*np.sqrt(2*np.pi))\n",
    "    zlognorm_AD = zfront_AD*np.exp(zexp_AD)\n",
    "    zwhere_are_NaNs = np.isnan(zlognorm_AD)\n",
    "    zlognorm_AD[zwhere_are_NaNs] = 0.0\n",
    "    zPsi_AD = zpowr*zlognorm_AD\n",
    "    \n",
    "    #Full transfer equations\n",
    "    Jtransfer = JPsi_DT + JPsi_AD\n",
    "    Htransfer = HPsi_DT + HPsi_AD\n",
    "    Ktransfer = KPsi_DT + KPsi_AD\n",
    "    gtransfer = gPsi_DT + gPsi_AD\n",
    "    rtransfer = rPsi_DT + rPsi_AD\n",
    "    itransfer = iPsi_DT + iPsi_AD\n",
    "    ztransfer = zPsi_DT + zPsi_AD\n",
    "    \n",
    "    plt.plot(tau,Jtransfer,'b', label='J')\n",
    "    plt.plot(tau,Htransfer,'r', label='H')\n",
    "    plt.plot(tau,Ktransfer,'g', label='K')\n",
    "    plt.plot(tau,gtransfer,'c', label='g')\n",
    "    plt.plot(tau,rtransfer,'m', label='r')\n",
    "    plt.plot(tau,itransfer,'y', label='i')\n",
    "    plt.plot(tau,ztransfer,'k', label='z')\n",
    "    plt.plot(tau,lognorm_DT,'k',label='DT')\n",
    "    plt.title('Light curves')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Delta mag')\n",
    "    plt.legend()\n",
    "    \n",
    "    return [Jtransfer,Htransfer,Ktransfer,gtransfer,rtransfer,itransfer,ztransfer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ=pm.summary(tracetransfer,names)\n",
    "#summ.loc[:,'mean'][0:27]\n",
    "#summ.loc[:,'mean'][0:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta=np.array(list(summ.loc[:,'mean'][0:27]))\n",
    "theta\n",
    "tau=np.linspace(1.5,3,1000)\n",
    "a = transfertest(theta,tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu,sigma,n = mmu,2*msig,3000\n",
    "\n",
    "def normal(x,mu,sigma):\n",
    "    return ( 2.*np.pi*sigma**2. )**-.5 * np.exp( -.5 * (x-mu)**2. / sigma**2. )\n",
    "\n",
    "x = np.random.normal(mu,sigma,n) \n",
    "y = normal(x,mu,sigma) \n",
    "y_log=normal(np.log(x),mu,sigma)\n",
    "\n",
    "plt.plot(x,y,'.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify simple model to save time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "yK,yKerr = np.loadtxt('Kband.txt', delimiter=',', usecols=(0,1), unpack=True)\n",
    "yi,yierr = np.loadtxt('iband.txt', delimiter=',', usecols=(0,1), unpack=True)\n",
    "X=np.linspace(58000,58900,5000)\n",
    "\n",
    "n_list = 499# Number of selected points\n",
    "the_list = list(range(len(X)))\n",
    "ind = random.sample(the_list, n_list)\n",
    "    \n",
    "yK=yK[ind]\n",
    "yKerr=yKerr[ind]\n",
    "XK=X[ind]\n",
    "yi=yi[ind]\n",
    "yierr=yierr[ind]\n",
    "Xi=X[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = 499 #Number of GP points\n",
    "Xf = np.linspace(np.min([XK,Xi]), np.max([XK,Xi]), nf)\n",
    "Xf=np.reshape(Xf,(len(Xf),1))\n",
    "tau=np.linspace(1.0,100.0,nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Xf,2e-6*Xf,'.')\n",
    "plt.plot(XK,yK,'.')\n",
    "plt.plot(Xi,yi,'.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlow=2.3#10\n",
    "mhigh=3.7#4.1#60\n",
    "mmu=(mhigh+mlow)/2.0\n",
    "msig=(mhigh-mlow)/2.0\n",
    "siglow=0.1\n",
    "sighigh=2.55\n",
    "sigmu=(sighigh+siglow)/2.0\n",
    "sigsig=(sighigh-siglow)/2.0\n",
    "#Different wavelength for different bands, not a free paramter \n",
    "#REMIR filters in nm\n",
    "#Kwav = 2150.0\n",
    "#Sloan filters for ROSS2 in nm\n",
    "#iwav = 769.8\n",
    "#Define constants \n",
    "#wav_0 = 1122.4#Reference wavelength in nm, use 500?\n",
    "#h = 6.626e-34#Plancks constant in J*s\n",
    "#c = 299792458.0#speed of light in m/s\n",
    "#k = 1.38e-23#Boltzmanns constant in J/K\n",
    "\n",
    "#b_max = 4.967\n",
    "\n",
    "#theano.compile.mode.Mode(linker='py', optimizer='fast_compile')\n",
    "#theano.compile.mode.Mode(linker='cvm', optimizer='fast_run')\n",
    "#theano.THEANO_FLAGS='device=cuda,floatX=float32'\n",
    "#theano.optimizer_including('cudnn')\n",
    "#theano.optimizer_including=conv_meta\n",
    "#dnn.enable=True\n",
    "#theano.config.lib.amdlibm='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as convmodel:\n",
    "    ############################################\n",
    "    #define driving function as Gaussian Process\n",
    "    ############################################\n",
    "    #find way to use g band as first guess of value \n",
    "    ℓ = pm.Bound(pm.Normal, lower=0.0,upper=0.71)('ℓ', mu=0.355, sigma=0.355)#timescale of variation for the driving function, order of days for UV\n",
    "    #REMEMBER time scale is 2*ℓ^2 so remember to rewrite as ℓ_true=2*ℓ^2\n",
    "    η = pm.Bound(pm.Normal, lower=0.0,upper=0.4)('η', mu=0.2, sigma=0.2)#long term standard deviation for the driving function\n",
    "    cov = η**2 * pm.gp.cov.Exponential(1, ls=ℓ)#using same cov as light curve interpolation\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    f = gp.prior(\"f\", X=Xf)\n",
    "    f = f.reshape((1,1,len(Xf),1))\n",
    "    \n",
    "    ##############\n",
    "    #Define priors\n",
    "    ##############\n",
    "    #Universal Dusty Torus parameters for the uniform temperature DT\n",
    "    sigma_DT=pm.Bound(pm.Normal, lower=siglow,upper=sighigh)('sigma_DT', mu=sigmu, sigma=sigsig)#needs a source for scale\n",
    "    m_DT=pm.Bound(pm.Normal, lower=mlow,upper=mhigh)('m_AD', mu=mmu, sigma=msig)#we expect serveral tens to hundreds of days from the nature letter\n",
    "    theta_DT=pm.Bound(pm.Normal, lower=2.3,upper=4.1)('theta_DT', mu=3.2,sigma=0.9)#add later when simple model is staple\n",
    "    #Accretion Disk paramters\n",
    "    #K band\n",
    "    Ksigma_AD=pm.Bound(pm.Normal, lower=siglow,upper=sighigh)('Ksigma_AD', mu=sigmu, sigma=sigsig)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    Ktheta_AD=0.0#pm.Normal('Ktheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    Km_AD=pm.Bound(pm.Normal, lower=mlow,upper=mhigh)('Km_AD', mu=mmu, sigma=msig)#AD has 3-5 times smaller lags than DT  \n",
    "    #i band\n",
    "    isigma_AD=pm.Bound(pm.Normal, lower=siglow,upper=sighigh)('isigma_AD', mu=sigmu, sigma=sigsig)#pm.TruncatedNormal('isigma_AD', mu=sigmu,sigma=sigsig,lower=siglow)# Shappee 2014 suggests somewhere between 0-20 days so log that \n",
    "    itheta_AD=0.0#pm.Normal('gtheta_AD',mu=0.0,sigma=10.0)#add later \n",
    "    im_AD=pm.Bound(pm.Normal, lower=mlow,upper=mhigh)('im_AD', mu=mmu, sigma=msig)#AD has 3-5 times smaller lags than DT \n",
    "    #BB and power law parameters\n",
    "    T=pm.Bound(pm.Normal, lower=6.90775527898 ,upper=7.74066440192)('T',mu=7.32420984045,sigma=0.41645456146)#taken from nature letter\n",
    "    K_0=pm.Bound(pm.Normal, lower=-2.3,upper=2.3)('K_0', mu=0, sigma=2.3)#powr/BB\n",
    "    index=pm.Bound(pm.Normal, lower=0.5,upper=3.0)('index', mu=1.5, sigma=0.5)#pm.Uniform('index',lower=0.5,upper=2.5)#pm.TruncatedNormal('index', mu=1.5, sigma=0.5,lower=0.0)#sign depends on diffmag definition change to -2 to -1\n",
    "    #Note for index: we have taken the transformation from F_nu to F_lamb into account with the index value.\n",
    "                         \n",
    "\n",
    "    \n",
    "    #Peak Black Body from uniform torus temperature\n",
    "    #wav_peak = 2.898*10**6/tt.exp(T)\n",
    "    #b_max = 4.967#h*c/(1e-9*wav_peak*k*tt.exp(T))\n",
    "    BB_max = -79.3575 + 5.0*T#the log of the peak wavelength blackbody#-5*tt.log(wav_peak)-tt.log( (tt.exp(b_max) - 1.0) )\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((tt.log((tau-tt.exp(theta_DT))/tt.exp(m_DT)))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-tt.exp(theta_DT))*sigma_DT*tt.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*tt.exp(exp_DT)\n",
    "    lognorm_DT = tt.switch(tt.isnan(lognorm_DT), 0.0, lognorm_DT)\n",
    "    \n",
    "\n",
    "    #Dusty Torus transfer equation for K band\n",
    "    Kb = 6692.0/tt.exp(T)\n",
    "    KBB = -38.36611560560854-tt.log(tt.exp(Kb) - 1.0)\n",
    "    KPsi_DT = (tt.exp(KBB)/tt.exp(BB_max))*lognorm_DT\n",
    "    #Dusty Torus transfer equation for i band\n",
    "    ib = 18690.0/tt.exp(T)\n",
    "    iBB = -33.230653704248226-tt.log(tt.exp(ib) - 1.0)\n",
    "    iPsi_DT = (tt.exp(iBB)/tt.exp(BB_max))*lognorm_DT   \n",
    "    \n",
    "\n",
    "    #Accretion Disk transfer equation for the K band\n",
    "    Kpowr = K_0+0.649998592333457*index   \n",
    "    Kexp_AD = -((tt.log((tau-Ktheta_AD)/tt.exp(Km_AD)))**2/(2*Ksigma_AD**2))\n",
    "    Kfront_AD = 1.0/((tau-Ktheta_AD)*Ksigma_AD*tt.sqrt(2*np.pi))\n",
    "    Klognorm_AD = Kfront_AD*tt.exp(Kexp_AD)\n",
    "    #Klognorm_AD = tt.switch(tt.isnan(Klognorm_AD), 0.0, Klognorm_AD)\n",
    "    KPsi_AD = tt.exp(Kpowr)*Klognorm_AD\n",
    "    #Accretion Disk transfer equation for the g band\n",
    "    ipowr = K_0-0.3770937879386054*index   \n",
    "    iexp_AD = -((tt.log((tau-itheta_AD)/tt.exp(im_AD)))**2/(2*isigma_AD**2))\n",
    "    ifront_AD = 1.0/((tau-itheta_AD)*isigma_AD*tt.sqrt(2*np.pi))\n",
    "    ilognorm_AD = tt.exp(ifront_AD)*tt.exp(iexp_AD)\n",
    "    #ilognorm_AD = tt.switch(tt.isnan(ilognorm_AD), 0.0, ilognorm_AD)\n",
    "    iPsi_AD = tt.exp(ipowr)*ilognorm_AD\n",
    "    \n",
    "    #########################\n",
    "    #Full transfer equations\n",
    "    #########################\n",
    "    \n",
    "    Ktransfer = KPsi_DT + KPsi_AD\n",
    "    Ktransfer = Ktransfer.reshape(((1,1,len(tau),1)))\n",
    "    itransfer = iPsi_DT + iPsi_AD\n",
    "    itransfer = itransfer.reshape(((1,1,len(tau),1)))\n",
    "\n",
    "    #The convolutions\n",
    "    ######################################################################\n",
    "    #'half': pad input with a symmetric border of filter rows // 2\n",
    "    #rows and filter columns // 2 columns, then perform a valid convolution. \n",
    "    #For filters with an odd number of rows and columns, \n",
    "    #this leads to the output shape being equal to the input shape.\n",
    "    ######################################################################\n",
    "\n",
    "    Kconvol=theano.tensor.nnet.conv2d(f,Ktransfer,border_mode='half')\n",
    "    Kcomp=interpolate(Xf[:,0],Kconvol[0,0,:,0],XK)\n",
    "    #Kcomp = pm.Deterministic('Kcomp', interpolate(Xf[:,0],Kconvol[0,0,:,0],XK))\n",
    "    \n",
    "    iconvol=theano.tensor.nnet.conv2d(f,itransfer,border_mode='half')\n",
    "    icomp=interpolate(Xf[:,0],iconvol[0,0,:,0],Xi)\n",
    "    #icomp = pm.Deterministic('icomp', interpolate(Xf[:,0],iconvol[0,0,:,0],Xi))\n",
    "    #Define likelihoods\n",
    "\n",
    "    #kK = pm.TruncatedNormal('kK', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "    #kg = pm.TruncatedNormal('kg', mu=1.0, sigma=1.0, lower=0.0, upper=3.0)\n",
    "\n",
    "    Klikelihood = pm.Normal('yK', mu=Kcomp, sigma=yKerr, observed=yK)\n",
    "    ilikelihood = pm.Normal('yi', mu=icomp, sigma=yierr, observed=yi)\n",
    "    \n",
    "    #the shape of mu and observed needs to be the same\n",
    "    ######################################################################\n",
    "    #max_treedepth, default=10\n",
    "    #The maximum tree depth. Trajectories are stopped when this depth is reached.\n",
    "    #early_max_treedepth, default=8\n",
    "    #The maximum tree depth during the first 200 tuning samples.\n",
    "    ######################################################################\n",
    "    \n",
    "    tracetransfer = pm.sample(1000,tune=1000,init='adapt_diag',chains=1,cores=8)\n",
    "    #tracetransfer = pm.sample(10000,tune=5000,chains=2,cores=8,step=pm.Metropolis())\n",
    "    #map_soln = xo.optimize(start=convmodel.test_point)\n",
    "    #step=xo.get_dense_nuts_step()\n",
    "    #tracetransfer = pm.sample(draws=2000,tune=1000,chains=1,cores=1,step=step)\n",
    "    #tracetransfer = pm.sample(1000,tune=500,init='advi+adapt_diag',chains=1)\n",
    "    #tracetransfer = pm.fit(300, method='svgd', inf_kwargs=dict(n_particles=100))\n",
    "    #tracetransfer = pm.fit(300,method=pm.SVGD(n_particles=1000, jitter=1.))\n",
    "    #tracetransfer= pm.fit(20000,method='fullrank_advi',callbacks=[pm.callbacks.CheckParametersConvergence(diff='absolute')])\n",
    "    #tracetransfer = pm.find_MAP()\n",
    "    \n",
    "    #test model valeus for nan or strange things    \n",
    "#     # make sure all test_value are finite\n",
    "#     print(convmodel.test_point)\n",
    "\n",
    "#     # make sure all logp are finite\n",
    "#     print(convmodel.check_test_point())\n",
    "    \n",
    "#     step = pm.HamiltonianMC()\n",
    "# q0 = step._logp_dlogp_func.dict_to_array(convmodel.test_point)\n",
    "# p0 = step.potential.random()\n",
    "# # make sure the potentials are all finite\n",
    "# print(p0)\n",
    "# logp, dlogp = step.integrator._logp_dlogp_func(q0)\n",
    "# print(logp)\n",
    "# print(dlogp)\n",
    "\n",
    "# # make sure velocity is finite\n",
    "# v = step.integrator._potential.velocity(p0)\n",
    "# print(v)\n",
    "# kinetic = step.integrator._potential.energy(p0, velocity=v)\n",
    "# print(kinetic)\n",
    "    \n",
    "#convmodel.profile(convmodel.logpt).summary()\n",
    "#convmodel.profile(pm.gradient(convmodel.logpt, convmodel.vars)).summary()\n",
    "#pm.model_to_graphviz(convmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracesimple=tracetransfer\n",
    "simplenames=['sigma_DT','m_DT','theta_DT','isigma_AD','itheta_AD','im_AD','Ksigma_AD','Ktheta_AD','Km_AD','T','K_0','index', 'η', 'ℓ']\n",
    "simplenames=['sigma_DT','m_DT','theta_DT','isigma_AD','im_AD','Ksigma_AD','Km_AD','T','K_0','index', 'η', 'ℓ']\n",
    "pm.plot_posterior(tracesimple, simplenames);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approx results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resu=tracesimple.sample(5000)\n",
    "pm.plot_posterior(resu,simplenames);\n",
    "pm.summary(resu,simplenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(resu, var_names=simplenames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_forest(tracesimple,\n",
    "               kind='ridgeplot',\n",
    "               var_names=['f'],\n",
    "               combined=False,\n",
    "               ridgeplot_overlap=3,\n",
    "               ridgeplot_alpha=.25,\n",
    "               colors='white',\n",
    "               figsize=(9, 7));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler convergence statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tracesimple['step_size_bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "accept = tracesimple.get_sampler_stats('mean_tree_accept', burn=1000)\n",
    "sb.distplot(accept, kde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracesimple['diverging'].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = tracesimple['energy']\n",
    "energy_diff = np.diff(energy)\n",
    "sb.distplot(energy - energy.mean(), label='energy')\n",
    "sb.distplot(energy_diff, label='energy diff')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.energyplot(tracesimple);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summ=pm.summary(tracesimple,simplenames)\n",
    "#print(summ.loc[:,'mean'])\n",
    "summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(tracesimple, var_names=simplenames);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.pairplot(tracesimple, var_names=simplenames, divergences=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "\n",
    "# plot the samples from the gp posterior with samples and shading\n",
    "from pymc3.gp.util import plot_gp_dist\n",
    "#plot_gp_dist(ax, tracetransfer[\"f\"], Xf);\n",
    "plot_gp_dist(ax, resu[\"f\"], Xf);\n",
    "# plot the data and the true latent function\n",
    "#plt.plot(X, y, 'ok', ms=3, alpha=0.5, label=\"Observed data\");\n",
    "\n",
    "# axis labels and title\n",
    "plt.xlabel(\"X\"); plt.ylabel(\"f(x)\");\n",
    "plt.title(\"Driving function\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_new = 300\n",
    "X_new = np.linspace(min(X_tot), max(X_tot), n_new)\n",
    "\n",
    "# add the GP conditional to the model, given the new X values\n",
    "with simpleconvmodel:\n",
    "    f_J = gp.conditional(\"f_J\", X_new)\n",
    "\n",
    "# Sample from the GP conditional distribution\n",
    "with simpleconvmodel:\n",
    "    pred_samples = pm.sample_posterior_predictive(tracesimple, vars=[f_J], samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the mean and standard deviation of the traces. \n",
    "mu = np.zeros(len(X_new))\n",
    "sd = np.zeros(len(X_new))\n",
    "\n",
    "for i in range(0,len(X_new)):\n",
    "    mu[i] = np.mean(pred_samples[\"f_J\"][:,i])\n",
    "    sd[i] = np.std(pred_samples[\"f_J\"][:,i])\n",
    "\n",
    "# draw plot\n",
    "fig = plt.figure(figsize=(12,5)); ax = fig.gca()\n",
    "\n",
    "# plot mean and 1σ intervals\n",
    "plt.plot(X_new, mu, 'r', lw=2, label=\"mean and 1σ region\");\n",
    "plt.plot(X_new, mu + 1*sd, 'r', lw=1); plt.plot(X_new, mu - 1*sd, 'r', lw=1);\n",
    "plt.fill_between(X_new.flatten(), mu - 1*sd, mu + 1*sd, color=\"r\", alpha=0.5)\n",
    "#plt.errorbar(XJ,mu,sd,fmt='r.',label='Driving function value at data points')\n",
    "\n",
    "# plot original data and true function\n",
    "#plt.plot(X, y, 'ok', ms=3, alpha=1.0, label=\"observed data\")\n",
    "#plt.errorbar(X, y, yerr,fmt='.',label=\"observed data\")\n",
    "\n",
    "plt.xlabel(\"t\");\n",
    "plt.ylabel(\"diffmag\")\n",
    "plt.title(\"predictive mean and 1σ interval\"); plt.legend();\n",
    "print(np.mean(sd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt=np.linspace(0,100,99)\n",
    "yt=10.0*xt+4.0\n",
    "comp=np.convolve(xt,yt,'same')\n",
    "yterr=np.random.rand(99)\n",
    "print(yterr)\n",
    "with pm.Model() as test:\n",
    "    \n",
    "    a=pm.Uniform('a',lower=7.5,upper=20.0)\n",
    "    b=pm.Uniform('b',lower=a/10.0,upper=a/2.0)\n",
    "    xin=xt.reshape(1,1,99,1)\n",
    "    muy=a*xin+b\n",
    "    compa=theano.tensor.nnet.conv2d(xin,muy,border_mode='half')\n",
    "    \n",
    "    likelihood = pm.Normal('y', mu=compa[0,0,:,0], sigma=yterr, observed=comp)\n",
    "\n",
    "    trace = pm.sample(4000,tune=1000,init='advi+adapt_diag',chains=2,cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(trace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
