{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"MKL_THREADING_LAYER\"]=\"GNU\"\n",
    "\n",
    "# 15-Sep-2019\n",
    "# Bo Milvang-Jensen\n",
    "# Very rudimentary script to read+plot ...\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "from theano.tensor import fft\n",
    "import theano.tensor.signal.conv\n",
    "\n",
    "# Read photometry catalogue created by my other script\n",
    "photfilename = 'F51_out_REMIR_ROS2.fits'\n",
    "data = fits.getdata(photfilename, 1)\n",
    "\n",
    "# The photometry catalogue contains aperture photometry in 25 different\n",
    "# apertures. If we number them 0..24, they correspond to diameters 1..25 arcsec\n",
    "apno = 10 # This is then 11 arcsec\n",
    "\n",
    "# The photometry catalogue contains photometry for the AGN plus some more\n",
    "# objects in the field, in this case the AGN + 6 more objetcs, so 7 in\n",
    "# total. The AGN is number 1, and the others 2, 3, etc.\n",
    "# This is seen in the column names, which end in _1, _2, etc.\n",
    "# E.g. the column MAG_APER_1 contains the aperture magnitudes (for all\n",
    "# 25 apertures) for the AGN.\n",
    "\n",
    "# Get the aperture magnitudes\n",
    "##foo = data['MAG_APER_1'] # has shape e.g. (767, 25), the 25 being the apertures\n",
    "mag_agn  = data['MAG_APER_1'][:,apno]\n",
    "mag_ref1 = data['MAG_APER_3'][:,apno] # I have found that _3 is good here\n",
    "mag_ref2 = data['MAG_APER_4'][:,apno]\n",
    "\n",
    "# Get the differential magnitudes\n",
    "delta_mag_agn_ref1 = mag_agn - mag_ref1\n",
    "delta_mag_ref2_ref1 = mag_ref2 - mag_ref1\n",
    "\n",
    "# Get the magnitude errors \n",
    "magerr_agn = data['MAGERR_APER_1'][:,apno]\n",
    "magerr_ref1 = data['MAGERR_APER_3'][:,apno]\n",
    "magerr_ref2= data['MAGERR_APER_4'][:,apno]\n",
    "\n",
    "# TODO Here I could loop over the filters, subtracting the median\n",
    "\n",
    "# For simplicity \"extract\" some arrays from the data\n",
    "filt = data['filter']\n",
    "mjd_obs = data['mjd_obs']\n",
    "\n",
    "# A simple plot of the J band differential mags, with the median subtracted\n",
    "# Do 'H' and 'K' in the same way\n",
    "maskJ = (filt == 'J')\n",
    "#print(magerr_ref1[mask])\n",
    "#plt.scatter(mjd_obs[mask], delta_mag_agn_ref1[mask]-np.median(delta_mag_agn_ref1[mask]))\n",
    "plt.errorbar(mjd_obs[maskJ], delta_mag_agn_ref1[maskJ]-np.median(delta_mag_agn_ref1[maskJ]), magerr_ref1[maskJ],fmt='b.')\n",
    "plt.title('test')\n",
    "plt.xlabel('MJD-OBS')\n",
    "plt.ylabel('delta mag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J band data\n",
    "xJ=np.asarray(mjd_obs[maskJ], dtype=float)\n",
    "nJ=len(xJ)\n",
    "XJ = np.reshape(xJ,(nJ,1))\n",
    "yJ=np.asarray(delta_mag_agn_ref1[maskJ]-np.median(delta_mag_agn_ref1[maskJ]), dtype=float)\n",
    "yJerr = np.array(magerr_ref1[maskJ], dtype=float)\n",
    "\n",
    "#H band data\n",
    "maskH = (filt == 'H')\n",
    "\n",
    "xHtemp=np.asarray(mjd_obs[maskH], dtype=float)\n",
    "xH=np.delete(xHtemp,(1,2))\n",
    "nH=len(xH)\n",
    "XH = np.reshape(xH,(nH,1))\n",
    "XH_new=np.linspace(min(XH),max(XH),100,dtype=np.float64)\n",
    "\n",
    "Hdelta_mag_agn_ref1=np.delete(delta_mag_agn_ref1[maskH],(1,2))\n",
    "yH=np.asarray(Hdelta_mag_agn_ref1-np.median(Hdelta_mag_agn_ref1), dtype=float)\n",
    "yHerrtemp = np.asarray(magerr_ref1[maskH], dtype=float)\n",
    "yHerr=np.delete(yHerrtemp,(1,2))\n",
    "\n",
    "#K band data\n",
    "maskK = (filt == 'K')\n",
    "xK=np.asarray(mjd_obs[maskK], dtype=float)\n",
    "nK=len(xK)\n",
    "XK = np.reshape(xK,(nK,1))\n",
    "yK=np.asarray(delta_mag_agn_ref1[maskK]-np.median(delta_mag_agn_ref1[maskK]), dtype=float)\n",
    "yKerr = np.asarray(magerr_ref1[maskK], dtype=float)\n",
    "\n",
    "#time array with all bands\n",
    "#be carefull with how XJ and xj acts \n",
    "X_tot= np.concatenate((xJ,xH,xK),axis=None)\n",
    "X_tot=np.reshape(X_tot,(len(X_tot),1))\n",
    "\n",
    "#combine all y values for guess\n",
    "Y_tot= np.concatenate((yJ,yH,yK),axis=None)\n",
    "Y_tot=np.reshape(Y_tot,(len(Y_tot),1))\n",
    "\n",
    "#time delay array\n",
    "ntau=49\n",
    "tau=np.linspace(1.0,100.0,ntau)\n",
    "tau=np.reshape(tau,(1,1,ntau,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xJ, yJ, yJerr,fmt='b.',label='J')\n",
    "plt.errorbar(xH, yH, yHerr,fmt='g.',label='H')\n",
    "plt.errorbar(xK, yK, yKerr,fmt='r.',label='K')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as convmodel:\n",
    "    \n",
    "    #define driving function as Gaussian Process\n",
    "    #find way to use g band as first guess of value \n",
    "    ℓ = pm.Uniform('ℓ', lower=1.0, upper=2.0*70.0)#pm.Bound(pm.Normal, lower=1.2574, upper=3.0*50.0*np.sqrt(2.0))('ℓ', mu=70.0, sigma=35.0)#timescale of variation for the driving function\n",
    "    η = pm.Uniform('η', lower=0.0, upper=1.0)#long term standard deviation for the driving function\n",
    "    cov = η**2 * pm.gp.cov.Exponential(1, ℓ)#using same cov as light curve interpolation\n",
    "    #const_func = pm.gp.mean.Constant(tt.mean(yJ))#long term mean. Should it be zero or the g-band value?\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    f = gp.prior(\"f\", X=X_tot)#has all time values for all bands, testval is for g-band diffmag values?\n",
    "    f = f.reshape((1,1,len(X_tot),1))\n",
    "    #print(len(f.tag.test_value[0,0,:,0]))\n",
    "    #print(f.tag.test_value)\n",
    "    \n",
    "    \n",
    "    #Define priors\n",
    "    \n",
    "    #Universal Dusty Torus parameters for the uniform temperature DT\n",
    "    sigma_DT=pm.Uniform('sigma_DT', lower=tt.log(1.1), upper=tt.log(50.0))#needs a source for scale\n",
    "    m_DT=pm.Uniform('m_DT', lower=10.0, upper=150.0)#we expect serveral tens to hundreds of days\n",
    "    theta_DT=pm.Uniform('theta_DT', lower=-np.max(tau)/1.2, upper=np.max(tau)/1.2)#add later when simple model is staple\n",
    "    \n",
    "    #Accretion Disk paramters\n",
    "    Jsigma_AD=pm.Uniform('Jsigma_AD', lower=tt.log(1.1), upper=tt.log(50.0))#needs a source for scale\n",
    "    Jm_AD=pm.Uniform('Jm_AD', lower=2.0, upper=50.0)#AD has 3-5 times smaller lags than DT \n",
    "    Jtheta_AD=pm.Uniform('Jtheta_AD', lower=-np.max(tau)/1.2, upper=np.max(tau)/1.2)#add later \n",
    "   \n",
    "    Hsigma_AD=pm.Uniform('Hsigma_AD', lower=tt.log(1.1), upper=tt.log(50.0))#needs a source for scale\n",
    "    Hm_AD=pm.Uniform('Hm_AD', lower=2.0, upper=50.0)#AD has 3-5 times smaller lags than DT\n",
    "    Htheta_AD=pm.Uniform('Htheta_AD', lower=-np.max(tau)/1.2, upper=np.max(tau)/1.2)#add later \n",
    "    \n",
    "    Ksigma_AD=pm.Uniform('Ksigma_AD', lower=tt.log(1.1), upper=tt.log(50.0))#needs a source for scale\n",
    "    Km_AD=pm.Uniform('Km_AD', lower=2.0, upper=50.0)#AD has 3-5 times smaller lags than DT\n",
    "    Ktheta_AD=pm.Uniform('Ktheta_AD', lower=-np.max(tau)/1.2, upper=np.max(tau)/1.2)#add later \n",
    "    \n",
    "    #BB and power law parameters\n",
    "    T=pm.Bound(pm.Normal, lower=1000.0, upper=2000.0)('T', mu=1400.0, sigma=100.0)#taken from nature letter\n",
    "    K_0=pm.Uniform('K_0', lower=0.0, upper=10.0)#is it BB/powr or powr/BB?\n",
    "    index=pm.Uniform('index', lower=0.0, upper=3.0)#sign depends on diffmag definition change to -2 to -1 for final?\n",
    "\n",
    "    #Different wavelength for different bands, not a free paramter \n",
    "    #REMIR filters in nm NEED DATASHEET\n",
    "    Jwav=1250.0\n",
    "    Hwav=1625.0\n",
    "    Kwav=2150.0\n",
    "    #Sloan filters for ROSS2 in nm\n",
    "    #gwav=475.4\n",
    "    #rwav= 620.4\n",
    "    #iwav=769.8\n",
    "    #zwav=966.5\n",
    "    \n",
    "\n",
    "    #Define constants \n",
    "    wav_0 = 500.0#Reference wavelength in nm, use 500?\n",
    "    h = 6.626e-34#Plancks constant in J*s\n",
    "    c = 299792458.0#speed of light in m/s\n",
    "    k = 1.38e-23#Boltzmanns constant in J/K\n",
    "    \n",
    "    #peak Black Body from uniform torus temperature\n",
    "    wav_peak = 2.898*10**6/T\n",
    "    b_max = h*c/(1e-9*wav_peak*k*T)\n",
    "    BB_max = 1.0/( (wav_peak**5) * (tt.exp(b_max) - 1.0) )\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((tt.log((tau-theta_DT)/m_DT))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-theta_DT)*sigma_DT*np.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*tt.exp(exp_DT)\n",
    "    lognorm_DT = tt.switch(tt.isnan(lognorm_DT), 0.0, lognorm_DT)\n",
    "    \n",
    "    #Dusty Torus transfer equation for J band\n",
    "    Jb = h*c/(1e-9*Jwav*k*T)\n",
    "    JBB = (1.0/( Jwav**5 * (tt.exp(Jb) - 1.0) ))/BB_max\n",
    "    JPsi_DT = JBB*lognorm_DT\n",
    "    \n",
    "    #Dusty Torus transfer equation for H band\n",
    "    Hb = h*c/(1e-9*Hwav*k*T)\n",
    "    HBB = (1.0/( Hwav**5 * (tt.exp(Hb) - 1.0) ))/BB_max\n",
    "    HPsi_DT = HBB*lognorm_DT\n",
    "    \n",
    "    #Dusty Torus transfer equation for K band\n",
    "    Kb = h*c/(1e-9*Kwav*k*T)\n",
    "    KBB = (1.0/( Kwav**5 * (tt.exp(Kb) - 1.0) ))/BB_max\n",
    "    KPsi_DT = KBB*lognorm_DT\n",
    "    \n",
    "    #Accretion Disk transfer equation for the J band\n",
    "    Jpowr = K_0*(Jwav/wav_0)**(index)    \n",
    "    Jexp_AD = -((tt.log((tau-Jtheta_AD)/Jm_AD))**2/(2*Jsigma_AD**2))\n",
    "    Jfront_AD = 1.0/((tau-Jtheta_AD)*Jsigma_AD*np.sqrt(2*np.pi))\n",
    "    Jlognorm_AD = Jfront_AD*tt.exp(Jexp_AD)\n",
    "    Jlognorm_AD = tt.switch(tt.isnan(Jlognorm_AD), 0.0, Jlognorm_AD)\n",
    "    JPsi_AD = Jpowr*Jlognorm_AD\n",
    "    \n",
    "    #Accretion Disk transfer equation for the H band\n",
    "    Hpowr = K_0*(Hwav/wav_0)**(index)    \n",
    "    Hexp_AD = -((tt.log((tau-Htheta_AD)/Hm_AD))**2/(2*Hsigma_AD**2))\n",
    "    Hfront_AD = 1.0/((tau-Htheta_AD)*Hsigma_AD*np.sqrt(2*np.pi))\n",
    "    Hlognorm_AD = Hfront_AD*tt.exp(Hexp_AD)\n",
    "    Hlognorm_AD = tt.switch(tt.isnan(Hlognorm_AD), 0.0, Hlognorm_AD)\n",
    "    HPsi_AD = Hpowr*Hlognorm_AD\n",
    "    \n",
    "    #Accretion Disk transfer equation for the K band\n",
    "    Kpowr = K_0*(Kwav/wav_0)**(index)    \n",
    "    Kexp_AD = -((tt.log((tau-Ktheta_AD)/Km_AD))**2/(2*Ksigma_AD**2))\n",
    "    Kfront_AD = 1.0/((tau-Ktheta_AD)*Ksigma_AD*np.sqrt(2*np.pi))\n",
    "    Klognorm_AD = Kfront_AD*tt.exp(Kexp_AD)\n",
    "    Klognorm_AD = tt.switch(tt.isnan(Klognorm_AD), 0.0, Klognorm_AD)\n",
    "    KPsi_AD = Kpowr*Klognorm_AD\n",
    "    \n",
    "    #Full transfer equations\n",
    "    Jtransfer = JPsi_DT + JPsi_AD\n",
    "    Htransfer = HPsi_DT + HPsi_AD\n",
    "    Ktransfer = KPsi_DT + KPsi_AD\n",
    "    \n",
    "    #The convolutions\n",
    "    #filter needs to be odd so tau is odd\n",
    "    Jconvol=theano.tensor.nnet.conv2d(f[:,:,0:len(xJ),:],Jtransfer,border_mode='half')\n",
    "    Hconvol=theano.tensor.nnet.conv2d(f[:,:,len(xJ):len(xJ)+len(xH),:],Htransfer,border_mode='half')\n",
    "    Kconvol=theano.tensor.nnet.conv2d(f[:,:,len(xJ)+len(xH):len(xJ)+len(xH)+len(xK),:],Ktransfer,border_mode='half')\n",
    "    #print(Hconvol.tag.test_value)\n",
    "    #Define likelihoods\n",
    "    #k = pm.Uniform('k', lower=1.0, upper=10.0)#Noise boost factor \n",
    "    Jlikelihood = pm.Normal('yJ', mu=Jconvol[0,0,:,0], sigma=yJerr, observed=yJ)\n",
    "    Hlikelihood = pm.Normal('yH', mu=Hconvol[0,0,:,0], sigma=yHerr, observed=yH)\n",
    "    Klikelihood = pm.Normal('yK', mu=Kconvol[0,0,:,0], sigma=yKerr, observed=yK)\n",
    "    #the shape of mu and observed needs to be the same \n",
    "    \n",
    "    tracetransfer = pm.sample(4000,tune=1000,init='advi+adapt_diag',chains=2,cores=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['index', 'K_0', 'T', 'Km_AD', 'Ksigma_AD', 'sigma_DT', 'Hm_AD', 'theta_DT', 'm_DT', 'Hsigma_AD', 'Jm_AD', 'Jsigma_AD', 'η', 'ℓ']\n",
    "# display the total number and percentage of divergent\n",
    "divergent = tracetransfer['diverging']\n",
    "print('Number of Divergent %d' % divergent.nonzero()[0].size)\n",
    "divperc = (divergent.nonzero()[0].size / (2*len(tracetransfer))) * 100\n",
    "print('Percentage of Divergent %.1f' % divperc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "divergent_point = defaultdict(list)\n",
    "\n",
    "chain_warn = tracetransfer.report._chain_warnings\n",
    "for i in range(len(chain_warn)):\n",
    "    for warning_ in chain_warn[i]:\n",
    "        if warning_.step is not None and warning_.extra is not None:\n",
    "            for RV in convmodel.free_RVs:\n",
    "                para_name = RV.name\n",
    "                divergent_point[para_name].append(warning_.extra[para_name])\n",
    "\n",
    "for RV in convmodel.free_RVs:\n",
    "    para_name = RV.name\n",
    "    divergent_point[para_name] = np.asarray(divergent_point[para_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracedf = pm.trace_to_dataframe(tracetransfer)\n",
    "plotorder = names\n",
    "tracedf = tracedf[plotorder]\n",
    "\n",
    "_, ax = plt.subplots(1, 2, figsize=(15, 4), sharex=True, sharey=True)\n",
    "ax[0].plot(tracedf.values[divergent == 0].T, color='k', alpha=.025)\n",
    "ax[0].plot(tracedf.values[divergent == 1].T, color='C2', lw=.5)\n",
    "\n",
    "ax[1].plot(tracedf.values[divergent == 0].T, color='k', alpha=.025)\n",
    "ax[1].plot(tracedf.values[divergent == 1].T, color='C2', lw=.5)\n",
    "divsp = np.hstack([divergent_point['Km_AD_interval__'][:,None],\n",
    "                  ])\n",
    "\n",
    "ax[1].plot(divsp.T, 'C3', lw=.5)\n",
    "plt.ylim([-20,40])\n",
    "plt.xticks(range(10), plotorder)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.summary(tracetransfer,names).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(tracetransfer, var_names=names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(tracetransfer,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mu,sigma,n = 0.0,35.,1000\n",
    "\n",
    "def normal(x,mu,sigma):\n",
    "    return ( 2.*np.pi*sigma**2. )**-.5 * np.exp( -.5 * (x-mu)**2. / sigma**2. )\n",
    "\n",
    "x = np.random.normal(mu,sigma,n) \n",
    "y = normal(x,mu,sigma) \n",
    "\n",
    "\n",
    "plt.plot(x,y,'.')\n",
    "#plt.plot(np.log(x),np.log(y),'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify simple model to save time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as simpleconvmodel:\n",
    "    \n",
    "    #define driving function as Gaussian Process\n",
    "    #find way to use g band as first guess of value \n",
    "    ℓ = pm.Uniform('ℓ', lower=1.0, upper=70.0)#pm.Bound(pm.Normal, lower=1.2574, upper=3.0*50.0*np.sqrt(2.0))('ℓ', mu=70.0, sigma=35.0)#timescale of variation for the driving function\n",
    "    η = pm.Uniform('η', lower=0.0, upper=0.7)#long term standard deviation for the driving function\n",
    "    cov = η**2 * pm.gp.cov.Exponential(1, ℓ)#using same cov as light curve interpolation\n",
    "    #const_func = pm.gp.mean.Constant(tt.mean(yJ))#long term mean. Should it be zero or the g-band value?\n",
    "    gp = pm.gp.Latent(cov_func=cov)\n",
    "    f = gp.prior(\"f\", X=XJ)#has all time values for all bands, testval is for g-band diffmag values?\n",
    "    f = f.reshape((1,1,len(XJ),1))\n",
    "    #print(len(f.tag.test_value[0,0,:,0]))\n",
    "    #print(f.tag.test_value)\n",
    "    \n",
    "    \n",
    "    #Define priors\n",
    "    \n",
    "    #Universal Dusty Torus parameters for the uniform temperature DT\n",
    "    sigma_DT=pm.Uniform('sigma_DT', lower=tt.log(1.5), upper=tt.log(50.0))#needs a source for scale\n",
    "    m_DT=pm.Uniform('m_DT', lower=10.0, upper=150.0)#we expect serveral tens to hundreds of days\n",
    "    theta_DT=pm.Uniform('theta_DT', lower=-np.max(tau), upper=np.max(tau)/1.2)#add later when simple model is staple\n",
    "    \n",
    "    #Accretion Disk paramters\n",
    "    Jsigma_AD=pm.Uniform('Jsigma_AD', lower=tt.log(1.5), upper=tt.log(50.0))#needs a source for scale\n",
    "    Jm_AD=pm.Uniform('Jm_AD', lower=2.0, upper=50.0)#AD has 3-5 times smaller lags than DT \n",
    "    Jtheta_AD=pm.Uniform('Jtheta_AD', lower=-np.max(tau), upper=np.max(tau)/1.2)#add later \n",
    "    \n",
    "    #BB and power law parameters\n",
    "    T=pm.Uniform('T', lower=1000.0, upper=2000.0)#('T', mu=1400.0, sigma=100.0)#taken from nature letter\n",
    "    K_0=pm.Uniform('K_0', lower=0.0, upper=10.0)#is it BB/powr or powr/BB?\n",
    "    index=pm.Uniform('index', lower=0.0, upper=3.0)#sign depends on diffmag definition change to -2 to -1 for final?\n",
    "\n",
    "    #Different wavelength for different bands, not a free paramter \n",
    "    #REMIR filters in nm NEED DATASHEET\n",
    "    Jwav=1250.0\n",
    "    Hwav=1625.0\n",
    "    Kwav=2150.0\n",
    "    #Sloan filters for ROSS2 in nm\n",
    "    #gwav=475.4\n",
    "    #rwav= 620.4\n",
    "    #iwav=769.8\n",
    "    #zwav=966.5\n",
    "    \n",
    "\n",
    "    #Define constants \n",
    "    wav_0 = 1000.0#Reference wavelength in nm, use 500?\n",
    "    h = 6.626e-34#Plancks constant in J*s\n",
    "    c = 299792458.0#speed of light in m/s\n",
    "    k = 1.38e-23#Boltzmanns constant in J/K\n",
    "    \n",
    "    #peak Black Body from uniform torus temperature\n",
    "    wav_peak = 2.898*10**6/T\n",
    "    b_max = h*c/(1e-9*wav_peak*k*T)\n",
    "    BB_max = 1.0/( (wav_peak**5) * (tt.exp(b_max) - 1.0) )\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((tt.log((tau-theta_DT)/m_DT))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-theta_DT)*sigma_DT*np.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*tt.exp(exp_DT)\n",
    "    lognorm_DT = tt.switch(tt.isnan(lognorm_DT), 0.0, lognorm_DT)\n",
    "    \n",
    "    #Dusty Torus transfer equation for J band\n",
    "    Jb = h*c/(1e-9*Jwav*k*T)\n",
    "    JBB = (1.0/( Jwav**5 * (tt.exp(Jb) - 1.0) ))/BB_max\n",
    "    JPsi_DT = JBB*lognorm_DT\n",
    "    \n",
    "    #Accretion Disk transfer equation for the J band\n",
    "    Jpowr = K_0*(Jwav/wav_0)**(index)    \n",
    "    Jexp_AD = -((tt.log((tau-Jtheta_AD)/Jm_AD))**2/(2*Jsigma_AD**2))\n",
    "    Jfront_AD = 1.0/((tau-Jtheta_AD)*Jsigma_AD*np.sqrt(2*np.pi))\n",
    "    Jlognorm_AD = Jfront_AD*tt.exp(Jexp_AD)\n",
    "    Jlognorm_AD = tt.switch(tt.isnan(Jlognorm_AD), 0.0, Jlognorm_AD)\n",
    "    JPsi_AD = Jpowr*Jlognorm_AD\n",
    "\n",
    "    #Full transfer equations\n",
    "    Jtransfer = JPsi_DT + JPsi_AD\n",
    "    \n",
    "    #The convolutions\n",
    "    #filter needs to be odd so tau is odd\n",
    "    Jconvol=theano.tensor.nnet.conv2d(f[:,:,0:len(xJ),:],Jtransfer,border_mode='half')\n",
    "\n",
    "    #Define likelihoods\n",
    "    #k = pm.Uniform('k', lower=1.0, upper=10.0)#Noise boost factor \n",
    "    Jlikelihood = pm.Normal('yJ', mu=Jconvol[0,0,:,0], sigma=yJerr, observed=yJ)\n",
    "    \n",
    "    #the shape of mu and observed needs to be the same \n",
    "    \n",
    "    tracesimple = pm.sample(4000, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tau=np.linspace(1.0,150.0,49)\n",
    "    \n",
    "    sigma_DT=1.0\n",
    "    m_DT=10.0\n",
    "    theta_DT=0.0\n",
    "    \n",
    "    #Accretion Disk paramters\n",
    "    Jsigma_AD=1.0\n",
    "    Jm_AD=5.0\n",
    "    Jtheta_AD=45.0\n",
    "    \n",
    "    #BB and power law parameters\n",
    "    T=1400.0\n",
    "    K_0=5.0\n",
    "    index=1.0\n",
    "    \n",
    "    #Different wavelength for different bands, not a free paramter \n",
    "    #REMIR filters in nm NEED DATASHEET\n",
    "    Jwav=1250.0 \n",
    "\n",
    "    #Define constants \n",
    "    wav_0 = 1000.0#Reference wavelength in nm, use 500?\n",
    "    h = 6.626e-34#Plancks constant in J*s\n",
    "    c = 299792458.0#speed of light in m/s\n",
    "    k = 1.38e-23#Boltzmanns constant in J/K\n",
    "    \n",
    "    #peak Black Body from uniform torus temperature\n",
    "    wav_peak = 2.898*10**6/T\n",
    "    b_max = h*c/(1e-9*wav_peak*k*T)\n",
    "    BB_max = 1.0/( (wav_peak**5) * (np.exp(b_max) - 1.0) )\n",
    "    \n",
    "    #Universal lognormal for Dusty Torus \n",
    "    exp_DT = -((np.log((tau-theta_DT)/m_DT))**2/(2*sigma_DT**2)) \n",
    "    front_DT = 1.0/((tau-theta_DT)*sigma_DT*np.sqrt(2*np.pi))\n",
    "    lognorm_DT = front_DT*np.exp(exp_DT)\n",
    "    where_are_NaNs1 = np.isnan(lognorm_DT)\n",
    "    lognorm_DT[where_are_NaNs1] = 0.0\n",
    "    \n",
    "    #Dusty Torus transfer equation for J band\n",
    "    Jb = h*c/(1e-9*Jwav*k*T)\n",
    "    JBB = (1.0/( Jwav**5 * (np.exp(Jb) - 1.0) ))/BB_max\n",
    "    JPsi_DT = JBB*lognorm_DT\n",
    "    \n",
    "    #Accretion Disk transfer equation for the J band\n",
    "    Jpowr = K_0*(Jwav/wav_0)**(index)    \n",
    "    Jexp_AD = -((np.log((tau-Jtheta_AD)/Jm_AD))**2/(2*Jsigma_AD**2))\n",
    "    Jfront_AD = 1.0/((tau-Jtheta_AD)*Jsigma_AD*np.sqrt(2*np.pi))\n",
    "    Jlognorm_AD = Jfront_AD*np.exp(Jexp_AD)\n",
    "    where_are_NaNs2 = np.isnan(Jlognorm_AD)\n",
    "    Jlognorm_AD[where_are_NaNs2] = 0.0\n",
    "    JPsi_AD = Jpowr*Jlognorm_AD\n",
    "\n",
    "    #Full transfer equations\n",
    "    Jtransfer = JPsi_DT + JPsi_AD\n",
    "    \n",
    "    #The convolutions\n",
    "    #filter needs to be odd so tau is odd\n",
    "    Jconvol=np.convolve(yJ,Jtransfer,'same')\n",
    "    \n",
    "plt.errorbar(XJ, yJ, yerr=yJerr, fmt=\".k\", capsize=0, label='muK')\n",
    "plt.plot(XJ, Jconvol, \":r\", label=\"conv\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"Time[d]\")\n",
    "plt.ylabel(\"diffmag\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
